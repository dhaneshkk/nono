---
title: Credential Injection
description: Keep API keys out of the sandbox with transparent credential injection
---

Credential injection keeps API keys out of the sandboxed process entirely. The agent sees a local HTTP URL and the proxy handles authentication transparently.

## How It Works

The proxy acts as a reverse proxy for configured credential routes. The agent sends plain HTTP to `localhost:<port>/<service>/...` and the proxy:

1. Strips the service prefix
2. Injects the real credential as an HTTP header
3. Forwards to the upstream over TLS
4. Streams the response back

```
Agent sends:  POST http://127.0.0.1:PORT/openai/v1/chat/completions
Proxy sends:  POST https://api.openai.com/v1/chat/completions
              Authorization: Bearer sk-... (injected from keystore)
```

The agent never sees the API key. Even if the agent is compromised, it cannot extract credentials from its own environment or memory.

Streaming responses (SSE for chat completions, MCP Streamable HTTP, A2A JSON-RPC) are forwarded without buffering.

## Quick Start

```bash
# 1. Store credentials in the system keystore
security add-generic-password -s "nono" -a "openai_api_key" -w "sk-..."  # macOS

# 2. Run with credential injection
nono run --allow-cwd --network-profile claude-code --proxy-credential openai -- my-agent
```

The proxy sets `OPENAI_BASE_URL=http://127.0.0.1:<port>/openai` in the child's environment. Most LLM SDKs respect this variable and redirect API calls through the proxy automatically.

## Storing Credentials

Credentials are stored in the system keyring under the service name `nono`. The username/account corresponds to the `credential_key` defined in `network-policy.json`:

| CLI Service | Keyring Username | Keyring Service |
|-------------|------------------|-----------------|
| `openai` | `openai_api_key` | `nono` |
| `anthropic` | `anthropic_api_key` | `nono` |
| `gemini` | `gemini_api_key` | `nono` |
| `google-ai` | `google_generative_ai_api_key` | `nono` |

### macOS

```bash
security add-generic-password -s "nono" -a "openai_api_key" -w "sk-..."
security add-generic-password -s "nono" -a "anthropic_api_key" -w "sk-ant-..."
security add-generic-password -s "nono" -a "gemini_api_key" -w "your-gemini-key"
```

### Linux

The `keyring` crate uses `service`, `username`, and `target` attributes. You must use these exact attribute names:

```bash
echo -n "sk-..." | secret-tool store --label="nono: openai_api_key" \
    service nono username openai_api_key target default

echo -n "sk-ant-..." | secret-tool store --label="nono: anthropic_api_key" \
    service nono username anthropic_api_key target default

echo -n "your-gemini-key" | secret-tool store --label="nono: gemini_api_key" \
    service nono username gemini_api_key target default
```

**Important:** Use `username` (not `account`) as the attribute name. The `target default` attribute is required for the keyring crate to find the entry.

## Environment Variables

When credential routes are configured, the proxy sets SDK-specific base URL environment variables:

| Route | Environment Variable | Value |
|-------|---------------------|-------|
| openai | `OPENAI_BASE_URL` | `http://127.0.0.1:<port>/openai` |
| anthropic | `ANTHROPIC_BASE_URL` | `http://127.0.0.1:<port>/anthropic` |

Most LLM SDKs (OpenAI Python, Anthropic Python, etc.) respect these variables and redirect API calls through the proxy automatically.

## Credential Route Configuration

The built-in `network-policy.json` defines default credential routes:

| Service | Upstream | Header | Format |
|---------|----------|--------|--------|
| openai | https://api.openai.com/v1 | Authorization | Bearer {} |
| anthropic | https://api.anthropic.com | x-api-key | {} |
| gemini | https://generativelanguage.googleapis.com | x-goog-api-key | {} |
| google-ai | https://generativelanguage.googleapis.com | x-goog-api-key | {} |

**Note:** OpenAI's upstream includes `/v1` because the OpenAI SDK expects the base URL to include the version prefix. Anthropic's SDK adds `/v1/messages` automatically, so its upstream is the root URL.

### Using Credentials in Profiles

User profiles can specify which credential services to enable in the `network` section:

```json
{
  "meta": { "name": "my-agent" },
  "filesystem": {
    "allow": ["$WORKDIR"]
  },
  "network": {
    "network_profile": "claude-code",
    "proxy_credentials": ["openai", "anthropic"]
  }
}
```

### Custom Credential Definitions

For APIs not covered by the built-in services, you can define custom credentials in your profile. This lets you use `--proxy-credential` with any API while keeping credentials out of the sandbox.

```json
{
  "meta": { "name": "my-agent" },
  "network": {
    "network_profile": "minimal",
    "proxy_credentials": ["openai", "telegram"],
    "custom_credentials": {
      "telegram": {
        "upstream": "https://api.telegram.org",
        "credential_key": "telegram_bot_token",
        "inject_header": "Authorization",
        "credential_format": "Bearer {}"
      }
    }
  }
}
```

| Field | Required | Default | Description |
|-------|----------|---------|-------------|
| `upstream` | Yes | - | Upstream URL to proxy requests to (must be HTTPS, or HTTP for localhost only) |
| `credential_key` | Yes | - | Keystore account name (alphanumeric and underscores only) |
| `inject_header` | No | `Authorization` | HTTP header to inject the credential into |
| `credential_format` | No | `Bearer {}` | Format string for the credential value (`{}` is replaced with the credential) |

Store the credential in the system keystore:

```bash
# macOS
security add-generic-password -s "nono" -a "telegram_bot_token" -w "your-bot-token"

# Linux
echo -n "your-bot-token" | secret-tool store --label="nono: telegram_bot_token" \
    service nono username telegram_bot_token target default
```

Then run with the custom credential:

```bash
nono run --profile my-agent --proxy-credential telegram -- my-bot
```

Custom credentials can also override built-in services. For example, to route OpenAI requests through a custom proxy:

```json
{
  "network": {
    "custom_credentials": {
      "openai": {
        "upstream": "https://my-openai-proxy.example.com/v1",
        "credential_key": "my_openai_key",
        "inject_header": "Authorization",
        "credential_format": "Bearer {}"
      }
    }
  }
}
```

#### Security Validation

Custom credentials are validated at startup:

- **Upstream URL must be HTTPS** (HTTP is only allowed for `localhost`, `127.0.0.1`, or `::1`)
- **Credential key must be alphanumeric** (letters, numbers, and underscores only)

Invalid configurations will fail with a clear error message before the sandbox is applied.

## Session Token Authentication

Reverse proxy requests are authenticated using an `X-Nono-Token` header containing the session token. The proxy generates a unique 256-bit token per session and passes it to the child via the `NONO_PROXY_TOKEN` environment variable. Every request to a credential route must include this header â€” requests without a valid token are rejected with `407 Proxy Authentication Required`.

This prevents other localhost processes from accessing the credential injection routes.

## Security Properties

- **Credentials never enter the sandbox** - The agent process has no access to API keys, even through environment variables or memory
- **Session token isolation** - Reverse proxy routes require `X-Nono-Token` authentication; CONNECT tunnels use `Proxy-Authorization`
- **Keystore-backed storage** - Credentials are loaded from the OS keyring (Keychain on macOS, Secret Service on Linux), not from plaintext files
- **Zeroized in memory** - Credential values are stored in `Zeroizing<String>` and wiped from memory on drop
- **Session-scoped** - Credentials are loaded once at proxy startup and never written to disk or logged
- **Header stripping** - The proxy strips any `Authorization` or `x-api-key` headers from the agent's request before injecting the real credential, preventing the agent from overriding the injected value

## Audit Logging

Reverse proxy requests are logged with the service name and status code, but credential values are never logged:

```
ALLOW REVERSE openai POST /v1/chat/completions -> 200
ALLOW REVERSE anthropic POST /v1/messages -> 200
```

## Next Steps

- [Network Filtering](/cli/features/network-proxy) - Host-level network filtering
- [Secrets Management](/cli/features/secrets) - Storing credentials in the system keystore
- [CLI Reference](/cli/usage/flags) - Complete flag documentation including network flags
