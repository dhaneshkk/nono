---
title: Credential Injection
description: Keep API keys out of the sandbox with transparent credential injection
---

Credential injection keeps API keys out of the sandboxed process entirely. The agent sees a local HTTP URL and the proxy handles authentication transparently.

## How It Works

The proxy acts as a reverse proxy for configured credential routes. The agent sends plain HTTP to `localhost:<port>/<service>/...` and the proxy:

1. Strips the service prefix
2. Injects the real credential as an HTTP header
3. Forwards to the upstream over TLS
4. Streams the response back

```
Agent sends:  POST http://127.0.0.1:PORT/openai/v1/chat/completions
Proxy sends:  POST https://api.openai.com/v1/chat/completions
              Authorization: Bearer sk-... (injected from keystore)
```

The agent never sees the API key. Even if the agent is compromised, it cannot extract credentials from its own environment or memory.

Streaming responses (SSE for chat completions, MCP Streamable HTTP, A2A JSON-RPC) are forwarded without buffering.

## Quick Start

```bash
# 1. Store credentials in the system keystore
security add-generic-password -s "nono-proxy" -a "openai" -w "sk-..."  # macOS

# 2. Run with credential injection
nono run --allow-cwd --network-profile claude-code --proxy-credential openai -- my-agent
```

The proxy sets `OPENAI_BASE_URL=http://127.0.0.1:<port>/openai` in the child's environment. Most LLM SDKs respect this variable and redirect API calls through the proxy automatically.

## Storing Credentials

Credentials are stored in the system keyring under the service name `nono-proxy`:

### macOS

```bash
security add-generic-password -s "nono-proxy" -a "openai" -w "sk-..."
security add-generic-password -s "nono-proxy" -a "anthropic" -w "sk-ant-..."
```

### Linux

```bash
secret-tool store --label="nono-proxy: openai" service nono-proxy username openai
secret-tool store --label="nono-proxy: anthropic" service nono-proxy username anthropic
```

## Environment Variables

When credential routes are configured, the proxy sets SDK-specific base URL environment variables:

| Route | Environment Variable | Value |
|-------|---------------------|-------|
| openai | `OPENAI_BASE_URL` | `http://127.0.0.1:<port>/openai` |
| anthropic | `ANTHROPIC_BASE_URL` | `http://127.0.0.1:<port>/anthropic` |

Most LLM SDKs (OpenAI Python, Anthropic Python, etc.) respect these variables and redirect API calls through the proxy automatically.

## Credential Route Configuration

The built-in `network-policy.json` defines default credential routes:

| Service | Upstream | Header | Format |
|---------|----------|--------|--------|
| openai | https://api.openai.com | Authorization | Bearer {} |
| anthropic | https://api.anthropic.com | x-api-key | {} |

### Custom Routes in Profiles

User profiles can specify credential routes in the `network` section:

```json
{
  "meta": { "name": "my-agent" },
  "filesystem": {
    "allow": ["$WORKDIR"]
  },
  "network": {
    "network_profile": "claude-code",
    "proxy_credentials": ["openai", "anthropic"]
  }
}
```

## Session Token Authentication

Reverse proxy requests are authenticated using an `X-Nono-Token` header containing the session token. The proxy generates a unique 256-bit token per session and passes it to the child via the `NONO_PROXY_TOKEN` environment variable. Every request to a credential route must include this header â€” requests without a valid token are rejected with `407 Proxy Authentication Required`.

This prevents other localhost processes from accessing the credential injection routes.

## Security Properties

- **Credentials never enter the sandbox** - The agent process has no access to API keys, even through environment variables or memory
- **Session token isolation** - Reverse proxy routes require `X-Nono-Token` authentication; CONNECT tunnels use `Proxy-Authorization`
- **Keystore-backed storage** - Credentials are loaded from the OS keyring (Keychain on macOS, Secret Service on Linux), not from plaintext files
- **Zeroized in memory** - Credential values are stored in `Zeroizing<String>` and wiped from memory on drop
- **Session-scoped** - Credentials are loaded once at proxy startup and never written to disk or logged
- **Header stripping** - The proxy strips any `Authorization` or `x-api-key` headers from the agent's request before injecting the real credential, preventing the agent from overriding the injected value

## Audit Logging

Reverse proxy requests are logged with the service name and status code, but credential values are never logged:

```
ALLOW REVERSE openai POST /v1/chat/completions -> 200
ALLOW REVERSE anthropic POST /v1/messages -> 200
```

## Next Steps

- [Network Filtering](/cli/features/network-proxy) - Host-level network filtering
- [Secrets Management](/cli/features/secrets) - Storing credentials in the system keystore
- [CLI Reference](/cli/usage/flags) - Complete flag documentation including network flags
